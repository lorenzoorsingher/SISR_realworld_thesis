\chapter*{Abstract}
\label{abstract}

\addcontentsline{toc}{chapter}{Summary}
Cameras have become omnipresent, inhabiting smartphones, vehicles, doorbells, and gadgets. Yet, not every situation demands high-end cameras due to various constraints. Post-capture methods like Super Resolution aim to refine image quality. Single-Image Super Resolution (SISR) reconstructs low-res (LR) images into high-res (HR) using powerful deep convolutional networks. Traditional methods artificially create LR images from HR, posing challenges in real-world scenarios due to discrepancies between training and testing data, especially when noise stems from unique sources like analog signals, as investigated here.

Remote aerial vehicles, needing precise navigation, employ live video feeds. While digital links suffice for slower crafts, they induce latency in faster, farther scenarios. First-Person View (FPV) drones often rely on low-res analog cameras, prioritizing low latency over image quality. A secondary high-res camera overcomes this, despite trade-offs like agility reduction, increased weight impacting battery life, and added costs. Usually, both cameras are fixed and point to the same direction, this presents the unique possibility of recording synchronized low-quality and high-quality videos, perfect for the creation of a specific dataset of paired LR and HR images.

What's left is to choose a SISR model and finetune on our newly extracted data. For this project we choose to compare the performance of four different models among the best currently performing algorithms, according to paperswithcode \cite{pwcode}: ESRGAN \cite{wang2018esrgan}, Real-ESRGAN \cite{wang2021realesrgan}, SwinIR \cite{liang2021swinir} and HAT-L \cite{chen2023activating}. These models can be divided in two classes: ESRGAN and Real-ESRGAN, as the names suggest, share a lot of similarities, they are both GAN based and the latter is an extension of the original network with some improvements such as the discriminator network. On the other hand, SwinIR and HAT-L have in common the implementation of transformers for SISR, HAT-L being the newer model and SwinIR on of the first to use this approach.

The nature of the dataset itself posed a challenge, as it was not clear from the start if the models would be able to learn the information even though the image pairs showed in part some differences in content, due to shutter speed, misalignment, perspective and whatnot. That being said the results are widely different from network to network, with the GAN-based models performing surprisingly well despite the architecture being older.

